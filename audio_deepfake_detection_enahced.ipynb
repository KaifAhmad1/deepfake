{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaifAhmad1/deepfake/blob/main/audio_deepfake_detection_enahced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  **Audio Deepfake Detection, Fake Calls, Spoofing, Fraud Calls and Voice Cloning Analysis for Defensive Forensics**\n",
        "This script provides a comprehensive forensic analysis pipeline for audio files, focusing on detecting signs of deepfakes, spoofing, and manipulation. It integrates various analysis techniques including signal processing, feature extraction, traditional ML/DSP-based detection methods, SpeechBrain models (stubbed for demonstration), and state-of-the-art multimodal LLMs via vLLM and Groq.\n"
      ],
      "metadata": {
        "id": "CWnBHisbDcnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy librosa soundfile matplotlib IPython webrtcvad pydub noisereduce pyAudioAnalysis speechbrain langchain openai langgraph transformers vllm requests ipywidgets audiomentations hmmlearn eyed3 langchain_community praat-parselmouth webrtcvad groq"
      ],
      "metadata": {
        "id": "ds9KD-Z5L4G8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import asyncio\n",
        "import time\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import numpy as np\n",
        "import torch\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import nest_asyncio\n",
        "import ipywidgets as widgets\n",
        "import webrtcvad\n",
        "import noisereduce as nr\n",
        "import parselmouth\n",
        "from pydub import AudioSegment\n",
        "from moviepy.editor import VideoFileClip\n",
        "from transformers import AutoTokenizer\n",
        "from vllm import LLM, EngineArgs, SamplingParams\n",
        "import IPython.display as ipd\n",
        "from IPython.display import display, clear_output, HTML, Image, Markdown\n",
        "\n",
        "# --- Optional Dependency Handling & Imports ---\n",
        "try:\n",
        "    import soundfile as sf\n",
        "    HAS_SOUNDFILE = True\n",
        "except ImportError:\n",
        "    print(\"[WARN] soundfile library not found (`pip install soundfile`). Some operations might be slower or fail.\")\n",
        "    HAS_SOUNDFILE = False\n",
        "\n",
        "try:\n",
        "    import pyloudnorm as pyln\n",
        "    HAS_PYLOUDNORM = True\n",
        "except ImportError:\n",
        "    print(\"[WARN] pyloudnorm library not found (`pip install pyloudnorm`). Loudness normalization disabled.\")\n",
        "    HAS_PYLOUDNORM = False\n",
        "\n",
        "try:\n",
        "    from scipy import signal\n",
        "    HAS_SCIPY = True\n",
        "except ImportError:\n",
        "    print(\"[WARN] scipy library not found (`pip install scipy`). De-humming feature disabled.\")\n",
        "    HAS_SCIPY = False\n",
        "\n",
        "try:\n",
        "    import seaborn as sns\n",
        "    HAS_SEABORN = True\n",
        "except ImportError:\n",
        "    print(\"[WARN] seaborn library not found (`pip install seaborn`). Enhanced plots disabled.\")\n",
        "    HAS_SEABORN = False\n",
        "\n",
        "# --- SpeechBrain & LLM Integrations ---\n",
        "from speechbrain.inference.speaker import SpeakerRecognition\n",
        "try:\n",
        "    from speechbrain.augment import AddNoise\n",
        "except ImportError:\n",
        "    AddNoise = None\n",
        "try:\n",
        "    from speechbrain.pretrained import EncoderClassifier, LanguageIdentification\n",
        "except ImportError:\n",
        "    print(\"[WARN] SpeechBrain pretrained models not fully available. Some features might be limited.\")\n",
        "    EncoderClassifier, LanguageIdentification = None, None\n",
        "\n",
        "try:\n",
        "    from groq import Groq, AsyncGroq\n",
        "    HAS_GROQ = True\n",
        "except ImportError:\n",
        "    print(\"[WARN] Groq library not installed (`pip install groq`). Groq report generation disabled.\")\n",
        "    HAS_GROQ = False\n",
        "    AsyncGroq = None\n",
        "\n",
        "# --- UI/Display ---\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "UQQXlXZEIcGF",
        "outputId": "75e08e46-6611-4611-9af6-f9abf6e4c001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] pyloudnorm library not found (`pip install pyloudnorm`). Loudness normalization disabled.\n",
            "[WARN] SpeechBrain pretrained models not fully available. Some features might be limited.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration & Constants ---\n",
        "GENERAL_PIPELINE_SETTINGS = {\n",
        "    \"TARGET_SR\": 16000,\n",
        "    \"VAD_AGGRESSIVENESS\": 2,\n",
        "    \"MAX_CONCURRENT_TASKS\": os.cpu_count() or 4,\n",
        "    \"PRINT_LEVEL\": \"INFO\",\n",
        "    \"LOUDNESS_TARGET_LUFS\": -23.0,\n",
        "    \"ENABLE_LOUDNESS_NORMALIZATION\": HAS_PYLOUDNORM and HAS_SOUNDFILE,\n",
        "    \"ENABLE_NOISE_REDUCTION\": True,\n",
        "    \"ENABLE_DEHUMMING\": HAS_SCIPY,\n",
        "    \"MAX_VLLM_TOKENS\": 350,\n",
        "    \"VLLM_TEMPERATURE\": 0.1,\n",
        "    \"GROQ_MODEL\": \"llama3-70b-8192\",\n",
        "    \"GROQ_TEMPERATURE\": 0.1,\n",
        "    \"VLLM_MODELS_TO_RUN\": [\"qwen2_audio\", \"ultravox\"],\n",
        "}\n",
        "\n",
        "MODEL_PATHS = {\n",
        "    \"SPKREC_MODEL_SOURCE\": \"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    \"ANTISPOOF_MODEL_SOURCE\": \"speechbrain/anti-spoofing-ecapa-voxceleb\",\n",
        "    \"LANGID_MODEL_SOURCE\": \"speechbrain/lang-id-commonlanguage_ecapa\",\n",
        "    \"EMOTION_MODEL_SOURCE\": \"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\",\n",
        "}\n",
        "\n",
        "# --- Resource Management ---\n",
        "executor = ThreadPoolExecutor(max_workers=GENERAL_PIPELINE_SETTINGS[\"MAX_CONCURRENT_TASKS\"], thread_name_prefix='ForensicWorker')\n",
        "vllm_engines = {}\n",
        "\n",
        "# --- Utility Functions ---\n",
        "def print_message(level, message):\n",
        "    levels = {\"DEBUG\": 0, \"INFO\": 1, \"WARN\": 2, \"ERROR\": 3}\n",
        "    if levels.get(level, 1) >= levels.get(GENERAL_PIPELINE_SETTINGS[\"PRINT_LEVEL\"], 1):\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        print(f\"{timestamp} [{level:<5}] {message}\")\n",
        "\n",
        "def get_file_extension(file_path):\n",
        "    return os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "def is_video_file(ext):\n",
        "    return ext in [\".mp4\", \".avi\", \".mov\", \".mkv\", \".webm\"]\n",
        "\n",
        "async def run_sync_in_executor(func, *args):\n",
        "    loop = asyncio.get_running_loop()\n",
        "    return await loop.run_in_executor(executor, func, *args)\n",
        "\n",
        "def set_device_for_engine():\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- Data Model ---\n",
        "class ForensicReport:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.file_path = kwargs.get(\"file_path\")\n",
        "        self.verdict = kwargs.get(\"verdict\", \"Error: Report not generated\")\n",
        "        self.mean_risk_score = kwargs.get(\"mean_risk_score\", -1.0)\n",
        "        self.confidence = kwargs.get(\"confidence\", 0.0)\n",
        "        self.all_model_scores = kwargs.get(\"all_model_scores\", {})\n",
        "        self.all_anomalies = kwargs.get(\"all_anomalies\", [])\n",
        "        self.groq_summary = kwargs.get(\"groq_summary\", \"N/A\")\n",
        "        self.vllm_outputs = kwargs.get(\"vllm_outputs\", {})\n",
        "        self.features = kwargs.get(\"features\", {})\n",
        "        self.metrics = kwargs.get(\"metrics\", {})\n",
        "        self.speaker_info = kwargs.get(\"speaker_info\", {})\n",
        "        self.quality_info = kwargs.get(\"quality_info\", {})\n",
        "        self.loudness_info = kwargs.get(\"loudness_info\", {})\n",
        "        self.compression_info = kwargs.get(\"compression_info\", {})\n",
        "        self.reverb_info = kwargs.get(\"reverb_info\", {})\n",
        "        self.edit_detection_info = kwargs.get(\"edit_detection_info\", {})\n",
        "        self.plots = kwargs.get(\"plots\", {})\n",
        "        self.processing_times = kwargs.get(\"processing_times\", {})\n",
        "        self.timestamp = kwargs.get(\"timestamp\", datetime.utcnow().isoformat())\n",
        "\n",
        "    def json(self, indent=2):\n",
        "        serializable_data = self._make_serializable(self.__dict__)\n",
        "        return json.dumps(serializable_data, indent=indent)\n",
        "\n",
        "    def _make_serializable(self, data):\n",
        "        if isinstance(data, dict):\n",
        "            return {k: self._make_serializable(v) for k, v in data.items()}\n",
        "        elif isinstance(data, list):\n",
        "            return [self._make_serializable(item) for item in data]\n",
        "        elif isinstance(data, np.ndarray):\n",
        "            return data.tolist()\n",
        "        elif isinstance(data, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64)):\n",
        "            return int(data)\n",
        "        elif isinstance(data, (np.float_, np.float16, np.float32, np.float64)):\n",
        "            if np.isnan(data): return None\n",
        "            if np.isinf(data): return None\n",
        "            return float(data)\n",
        "        elif isinstance(data, (np.complex_, np.complex64, np.complex128)):\n",
        "            return {'real': data.real, 'imag': data.imag}\n",
        "        elif isinstance(data, (np.bool_)):\n",
        "            return bool(data)\n",
        "        elif isinstance(data, (np.void)):\n",
        "            return None\n",
        "        return data"
      ],
      "metadata": {
        "id": "A4UMam1_IcI0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wh0Vt0gRIcMT"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}